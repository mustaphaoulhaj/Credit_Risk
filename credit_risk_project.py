# -*- coding: utf-8 -*-
"""Credit Risk Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11SfpJLa8MUnMGjsdZQ5yH97Os6j--fdc

# Import des bibliothèques nécessaires
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import chi2_contingency
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import statsmodels.api as sm
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from keras.models import Sequential
from keras.layers import Dense
import xgboost as xgb
import lightgbm as lgb
from prettytable import PrettyTable
from colorama import Fore, Style

"""# Data"""

# Charger les données depuis le fichier Excel
data = pd.read_excel('/content/german_credit_data.xlsx')

data.head()

"""# Statistiques descriptives"""

# @title Travail
data.groupby('Travail').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Duration

data['Duration'].plot(kind='hist', bins=20, title='Duration')
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Montant_Credit

data['Montant_Credit'].plot(kind='hist', bins=20, title='Montant_Credit')
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Age

data['Age'].plot(kind='hist', bins=20, title='Age')
plt.gca().spines[['top', 'right',]].set_visible(False)

# Calcul de la corrélation de Pearson entre les variables quantitatives

# Sélectionner les variables spécifiques
donnees_selectionnees = data[['Age', 'Montant_Credit', 'Duration']]

# Calcul de la matrice de corrélation entre les variables quantitatives
matrice_corr = donnees_selectionnees.corr()
plt.figure(figsize=(8, 6))
sns.heatmap(matrice_corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.show()

"""Commentaire : La corrélation positive de 0,62 entre le montant du crédit et la durée indique que la durée du prêt augmente, le montant du crédit tend également à augmenter."""

X = "Travail"
Y = "Risque"

table_contingence = data[[X, Y]].pivot_table(index=X, columns=Y, aggfunc=len).fillna(0).astype(int)

# Afficher la table de contingence
print("Table de contingence :")
print(table_contingence)
print()

# Calculer le test du chi-deux
stat, p_value, dof, expected = chi2_contingency(table_contingence)
print("Statistique du test du chi-deux :", stat)
print("Valeur-p :", p_value)
print("Degrés de liberté :", dof)

"""Commentaire : Il n'y a pas de relation significative entre le travail et le risque de crédit, car p_value=0.6 > 5%

# Transformation des données
"""

# Sélectionner les données quantitatives
Numerical_data = data[['Age', 'Travail', 'Montant_Credit', 'Duration']]
scaler= StandardScaler()
# Appliquer la standardisation
Data_standard = scaler.fit_transform(Numerical_data)
print(Data_standard)

# @title Risque de crédit

# Calculer les valeurs pour le diagramme circulaire
risque_counts = data['Risque'].value_counts()

# Créer le diagramme circulaire
plt.figure(figsize=(4 , 4))
plt.pie(risque_counts, labels=risque_counts.index, autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'])
plt.title('Répartition du risque de crédit')
plt.show()

# Créer une dataframe contenant les données standardisées
df_Data_standard = pd.DataFrame(Data_standard)

# Ajouter la variable 'Risque' à la dataframe
df_Data_standard['Risque'] = data['Risque']

# Renommer les colonnes de la dataframe
df_Data_standard.columns = ['Age', 'Travail', 'Montant_Credit', 'Duration', 'Risque']

df_Data_standard['Risque']=df_Data_standard['Risque'].replace({'good': 1, 'bad':0})

X=df_Data_standard.drop('Risque', axis=1)
y=df_Data_standard.loc[:, ['Risque']]

print(X)

print(y)

# Diviser les données en 2 échantillions (Train : 70% & Test : 30%)
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=42)

"""# Estimation de probabilité de défaut (PD)

## Régression logistique
"""

Logit= sm.Logit(y_train, X_train)
Model1=Logit.fit()
print(Model1.summary())

# Prédire les probabilités sur l'ensemble de test
y_pred_proba = Model1.predict(X_test)

# Calculer l'AUC-ROC
auc_roc = roc_auc_score(y_test, y_pred_proba)

# Courbe ROC

fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.plot(fpr, tpr, label='AUC ROC (Surface = %0.2f)' % auc_roc)
plt.plot([0, 1], [0, 1], 'k--')  # diagonal line
plt.xlabel('Taux de faux positifs')
plt.ylabel('Taux de vrais positifs')
plt.title('Courbe ROC - Modèle Régression logistique')
plt.legend(loc='lower right')
plt.show()

"""## SVM"""

# Créer le modèle SVM
svm_model = SVC(kernel='linear', probability=True)
svm_model.fit(X_train, y_train)

# Estimer les probabilités des données de test
y_proba_svm = svm_model.predict_proba(X_test)[:, 1]

# Calculer le score AUC-ROC
auc_roc_svm = roc_auc_score(y_test, y_proba_svm)

# Calculer la courbe ROC
fpr_svm, tpr_svm, _ = roc_curve(y_test, y_proba_svm)

# Courbe ROC
plt.plot(fpr_svm, tpr_svm, label=f'AUC = {auc_roc_svm:.2f}')
plt.plot([0, 1], [0, 1], 'k--')  # Ligne en pointillés pour la référence aléatoire
plt.xlabel('Taux de faux positifs')
plt.ylabel('Taux de vrais positifs')
plt.title('Courbe ROC - Modèle SVM')
plt.legend(loc='lower right')
plt.show()

"""## Forêtes aléatoires"""

# Créer le modèle de forêt aléatoire
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Estimer les probabilités des données de test
y_proba_rf = rf_model.predict_proba(X_test)[:, 1]

# Calculer le score AUC-ROC
auc_roc_rf = roc_auc_score(y_test, y_proba_rf)

# Calculer la courbe ROC
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)

# Courbe ROC
plt.plot(fpr_rf, tpr_rf, label=f'AUC = {auc_roc_rf:.2f}')
plt.plot([0, 1], [0, 1], 'k--')  # Ligne en pointillés pour la référence aléatoire
plt.xlabel('Taux de faux positifs')
plt.ylabel('Taux de vrais positifs')
plt.title('Courbe ROC - Modèle de Forêts Aléatoires')
plt.legend(loc='lower right')
plt.show()

"""## Réseau de neurones"""

# Créer le modèle de réseau de neurones
model = Sequential()
model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compiler le modèle
model.compile(optimizer='adam', loss='binary_crossentropy')

# Entraîner le modèle
model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)

# Obtenir les prédictions brutes
y_pred_nn = model.predict(X_test)

# Appliquer la fonction sigmoïde pour obtenir les probabilités
y_proba_nn = 1 / (1 + np.exp(-y_pred_nn))

# Calculer le score AUC-ROC
auc_roc_nn = roc_auc_score(y_test, y_proba_nn)

# Calculer la courbe ROC
fpr_nn, tpr_nn, _ = roc_curve(y_test, y_proba_nn)

# Courbe ROC
plt.plot(fpr_nn, tpr_nn, label=f'AUC = {auc_roc_nn:.2f}')
plt.plot([0, 1], [0, 1], 'k--')  # Ligne en pointillés pour la référence aléatoire
plt.xlabel('Taux de faux positifs')
plt.ylabel('Taux de vrais positifs')
plt.title('Courbe ROC - Modèle de Réseau de Neurones')
plt.legend(loc='lower right')
plt.show()

"""## XGBoost

"""

# Créer le modèle XGBoost
model_xgb = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=3,
    learning_rate=0.1,
    random_state=42
)

# Entraîner le modèle
model_xgb.fit(X_train, y_train)

# Prédire les probabilités des données de test
y_proba_xgb = model_xgb.predict_proba(X_test)[:, 1]

# Calculer le score AUC-ROC
auc_roc_xgb = roc_auc_score(y_test, y_proba_xgb)

# Calculer la courbe ROC
fpr, tpr, thresholds = roc_curve(y_test, y_proba_xgb)

# Tracer la courbe ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label='Courbe ROC (AUC = %0.2f)' % auc_roc_xgb)
plt.plot([0, 1], [0, 1], color='black', linestyle='--')
plt.xlabel('Taux de faux positifs')
plt.ylabel('Taux de vrais positifs')
plt.title('Courbe ROC du modèle XGBoost')
plt.legend(loc="lower right")
plt.show()

"""## LightGBM"""

# Créer le modèle LightGBM
model_lgb = lgb.LGBMClassifier(
    n_estimators=100,
    max_depth=3,
    learning_rate=0.1,
    random_state=42
)

# Entraîner le modèle
model_lgb.fit(X_train, y_train)

# Prédire les probabilités des données de test
y_proba_lgb = model_lgb.predict_proba(X_test)[:, 1]

# Calculer le score AUC-ROC
auc_roc_lgb = roc_auc_score(y_test, y_proba_lgb)

# Calculer la courbe ROC
fpr, tpr, thresholds = roc_curve(y_test, y_proba_lgb)

# Tracer la courbe ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label='Courbe ROC (AUC = %0.2f)' % auc_roc_lgb)
plt.plot([0, 1], [0, 1], color='black', linestyle='--')
plt.xlabel('Taux de faux positifs')
plt.ylabel('Taux de vrais positifs')
plt.title('Courbe ROC du modèle LightGBM')
plt.legend(loc="lower right")
plt.show()

"""# Conclusion"""

# Créer un tableau
table = PrettyTable()

# Ajouter des colonnes
table.field_names = ["Modèle", "AUC"]

# Ajouter des données avec LightGBM en bleu
table.add_row([f"{Fore.BLUE}LightGBM{Style.RESET_ALL}", f"{Fore.BLUE}0.67{Style.RESET_ALL}"])
table.add_row(["Réseau de neurones", 0.62])
table.add_row(["Forêts aléatoires", 0.62])
table.add_row(["XGBoost", 0.60])
table.add_row(["Régression logistique", 0.60])
table.add_row([f"{Fore.RED}SVM{Style.RESET_ALL}", f"{Fore.RED}0.54{Style.RESET_ALL}"])

# Afficher le tableau
print(table)

"""Parmi les modèles déployés, **LightGBM** a obtenu le meilleur score avec **0,67**, suivi du réseau de neurones et des forêts aléatoires avec 0,62. Pour renforcer la précision des modèles, nous pouvons utiliser la validation croisée. Cette technique permet d'évaluer la capacité du modèle à généraliser sur de nouvelles données et à réduire les biais.

L'estimation de la probabilité de défaut est un élément crucial pour la gestion du risque de crédit et est utilisée de diverses manières :


* **Tarification des prêts :** Déterminer les taux d'intérêt en fonction du risque de crédit. Les emprunteurs à risque élevé se voient généralement facturer des taux plus élevés.
* **Provisionnement et adéquation du capital :** Estimer les provisions et le capital nécessaires pour couvrir les pertes potentielles liées au crédit. Les régulateurs exigent des institutions financières qu'elles disposent de suffisamment de capital pour faire face au risque de crédit.
* **Gestion du portefeuille de crédit :** Surveiller et gérer le risque de crédit global du portefeuille. Identifier les concentrations de risques et mettre en œuvre des stratégies pour atténuer ces risques.
* **Décision en matière de crédit :** Aider à prendre des décisions de prêt éclairées en évaluant la solvabilité des emprunteurs. Les institutions financières peuvent utiliser les estimations de PD pour fixer des limites de crédit, approuver ou refuser des demandes de prêt et déterminer les exigences de garantie appropriées.
"""